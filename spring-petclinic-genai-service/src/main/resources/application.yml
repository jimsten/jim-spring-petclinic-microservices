spring:
  main:
    web-application-type: reactive
  application:
    name: genai-service
  profiles:
    active: production
  config:
    import: optional:configserver:${CONFIG_SERVER_URL:http://localhost:8888/},optional:classpath:/creds.yaml
  ai:
    chat:
      client:
        enabled: true
    # These apply when using spring-ai-azure-openai-spring-boot-starter
    azure:
      openai:
        api-key: ${AZURE_OPENAI_KEY}
        endpoint: ${AZURE_OPENAI_ENDPOINT}
        chat:
          options:
            temperature: 0.7
            deployment-name: gpt-4o
    # These apply when using spring-ai-openai-spring-boot-starter
    openai:
                 base-url: https://api.deepseek.com
                 api-key: ${DEEPSEEK_API_KEY}
                 chat:
                   options:
                     model: deepseek-chat
                     temperature: 0.7


logging:
  level:
    org:
      springframework:
        ai:
          chat:
            client:
              advisor: DEBUG
---
spring:
  config:
    activate:
      on-profile: docker
    import: configserver:http://config-server:8888
